{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i have a challenge in nlp \n",
    "Beginnerâ€™s challenge : \n",
    "\n",
    "Description : Email spam classification is a NLP project focused on developing a system capable of accurately distinguishing between spam and non-spam emails. The goal is to train a model using a dataset containing labeled email data, where each email is categorized as either spam or non-spam.\n",
    "Dataset : they provided us with a dataset containing three files one for emails that are spam one for the ones that are not spam and the last for the ones that are not sure if spam or not\n",
    "\n",
    "can you give me how to solve this ? i'm a beginer in nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# my data is separated (every email is in a file) and i want to make them into a csv file with the following columns\n",
    "# email | label\n",
    "# where label is the content of the file\n",
    "# i will use pandas to do this\n",
    "# the data is in the easy_ham , hard_ham and spam_2 folders\n",
    "\n",
    "import os\n",
    "import email\n",
    "\n",
    "# get the data\n",
    "data = []\n",
    "for folder in ['easy_ham', 'spam_2']:\n",
    "    # the emails in the easy_ham folder are not spam\n",
    "    # the emails in the spam_2 folder are spam\n",
    "    label = 0 if folder == 'easy_ham' else 1\n",
    "    for file in os.listdir(folder):\n",
    "        with open(f'{folder}/{file}', 'r', errors='replace') as f:\n",
    "            \n",
    "            email_str = f.read()\n",
    "            data.append([email_str, label])\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# create a dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# save the dataframe to a csv file\n",
    "df.to_csv('emails.csv', index=False)\n",
    "print('done')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      0  1\n",
      "0     From exmh-workers-admin@redhat.com  Thu Aug 22...  0\n",
      "1     From Steve_Burt@cursor-system.com  Thu Aug 22 ...  0\n",
      "2     From timc@2ubh.com  Thu Aug 22 13:52:59 2002\\n...  0\n",
      "3     From irregulars-admin@tb.tf  Thu Aug 22 14:23:...  0\n",
      "4     From exmh-users-admin@redhat.com  Thu Aug 22 1...  0\n",
      "...                                                 ... ..\n",
      "3943  From tba@insiq.us  Wed Dec  4 11:46:34 2002\\nR...  1\n",
      "3944  Return-Path: <raye@yahoo.lv>\\nReceived: from u...  1\n",
      "3945  From cweqx@dialix.oz.au  Tue Aug  6 11:03:54 2...  1\n",
      "3946  From ilug-admin@linux.ie  Wed Dec  4 11:52:36 ...  1\n",
      "3947  mv 00001.317e78fa8ee2f54cd4890fdc09ba8176 0000...  1\n",
      "\n",
      "[3948 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# read the csv file\n",
    "df = pd.read_csv('emails.csv')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get_payload'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(folder):\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 25\u001b[0m             body \u001b[38;5;241m=\u001b[39m \u001b[43memail_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_payload\u001b[49m(decode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# create a dataframe\u001b[39;00m\n\u001b[0;32m     28\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memail\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'get_payload'"
     ]
    }
   ],
   "source": [
    "\"\"\"Some hints (more like ideas to keep in mind) when working on NLP challenge 1: spam classification\n",
    "\n",
    "As you know so far, the dataset is organized into three folders: two contain non-spam (ham) emails (text files), while the third folder contains spam emails.\n",
    "\n",
    "All emails do follow a specific format, which will aid in parsing and extracting metadata and the mail body.\n",
    "\n",
    "Decide on the features you want to extract from each email. Think what would help you identify if an email is a spam or not? You might need to go back to this point later to modify the model, but keep it simple to start.\n",
    "\n",
    " Main challenge 1: How to extract meta data and mail body from the mails text in order to generate the dataset. You can think about parsing data manually, or maybe there's a library ? ðŸ‘€\n",
    "\n",
    "Once you have managed to get the information you want from each mail, you can build the dataset, but you still need to give each one a target column (this is a supervised problem).\n",
    "\"\"\"\n",
    "\n",
    "# i will use the email module to parse the emails\n",
    "\n",
    "# get the data\n",
    "data = []\n",
    "\n",
    "for folder in ['easy_ham', 'hard_ham', 'spam_2']:\n",
    "    # the emails in the easy_ham and hard_ham folder are not spam\n",
    "    # the emails in the spam_2 folder are spam\n",
    "    label = 0 if folder in ['easy_ham', 'hard_ham'] else 1\n",
    "    for file in os.listdir(folder):\n",
    "        with open(f'{folder}/{file}', 'r', errors='replace') as f:\n",
    "            email_str = f.read()\n",
    "            email_obj = email.message_from_string(email_str)\n",
    "            # get the body of the email\n",
    "            body = ''\n",
    "            if email_obj.is_multipart():\n",
    "                for part in email_obj.walk():\n",
    "                    content_type = part.get_content_type()\n",
    "                    content_disposition = str(part.get('Content-Disposition'))\n",
    "                    try:\n",
    "                        body = part.get_payload(decode=True).decode()\n",
    "                    except:\n",
    "                        pass\n",
    "            else:\n",
    "                body = email_obj.get_payload(decode=True).decode()\n",
    "            data.append([body, label])\n",
    "\n",
    "# create a dataframe\n",
    "df = pd.DataFrame(data, columns=['email', 'label'])\n",
    "\n",
    "# save the dataframe to a csv file\n",
    "df.to_csv('emails.csv', index=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_header(email):\n",
    "    \"\"\"remove the header from an email\"\"\"\n",
    "    return email[email.index('\\n\\n'):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def is_url(s):\n",
    "    url = re.match(\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|\" \"[!*\\(\\), ]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", s)\n",
    "    if url is None:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def url_converter(words):\n",
    "    for i, word in enumerate(words):\n",
    "        if is_url(word):\n",
    "            words[i] = 'URL'\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_converter(words):\n",
    "    for i, word in enumerate(words):\n",
    "        if word.isdigit():\n",
    "            words[i] = 'NUM'\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(email):\n",
    "    new_email = \"\"\n",
    "    for c in email:\n",
    "        if c.isalnum() or c.isspace():\n",
    "            new_email += c\n",
    "    return new_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
