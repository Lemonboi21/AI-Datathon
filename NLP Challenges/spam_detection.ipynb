{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unziping the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "def extract(zip_file_path):\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "\n",
    "      zip_ref.extractall(extracted_dir)\n",
    "\n",
    "      for filename in os.listdir(extracted_dir):\n",
    "          file_path = os.path.join(extracted_dir, filename)\n",
    "          if os.path.isfile(file_path):\n",
    "              with open(file_path, 'r', encoding='utf-8') as file:\n",
    "\n",
    "                  content = file.read()\n",
    "\n",
    "# extracting :\n",
    "easy_ham = 'easy_ham.zip'\n",
    "hard_ham = 'hard_ham.zip'\n",
    "spam = 'spam_2.zip'\n",
    "\n",
    "extracted_dir = 'data/'\n",
    "\n",
    "extract(easy_ham)\n",
    "extract(hard_ham)\n",
    "extract(spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# get the data\n",
    "data = []\n",
    "for folder in ['data/easy_ham', 'data/spam_2' , 'data/hard_ham']:\n",
    "    \n",
    "    lable = 0\n",
    "    for file in os.listdir(folder):\n",
    "        with open(f'{folder}/{file}', 'r', errors='replace') as f:\n",
    "            if folder == 'spam_2':\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 0\n",
    "            email_str = f.read()\n",
    "            data.append([email_str, label])\n",
    "\n",
    "# create a dataframe\n",
    "df = pd.DataFrame(data)\n",
    "df.columns = ['email', 'label']\n",
    "\n",
    "# save the dataframe to a csv file\n",
    "df.to_csv('emails.csv', index=False)\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  email  label\n",
      "0     From exmh-workers-admin@redhat.com  Thu Aug 22...      0\n",
      "1     From Steve_Burt@cursor-system.com  Thu Aug 22 ...      0\n",
      "2     From timc@2ubh.com  Thu Aug 22 13:52:59 2002\\n...      0\n",
      "3     From irregulars-admin@tb.tf  Thu Aug 22 14:23:...      0\n",
      "4     From exmh-users-admin@redhat.com  Thu Aug 22 1...      0\n",
      "...                                                 ...    ...\n",
      "4193  Return-Path: ler@lerami.lerctr.org\\nDelivery-D...      0\n",
      "4194  Return-Path: ler@lerami.lerctr.org\\nDelivery-D...      0\n",
      "4195  From bounce-ora_webprog-1083425@newsletter.ore...      0\n",
      "4196  Return-Path: linux-announce-recipients-owner-m...      0\n",
      "4197  Return-Path: <test-admin@lists.sourceforge.net...      0\n",
      "\n",
      "[4198 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# read the csv file\n",
    "df = pd.read_csv('emails.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Mon, 9 Sep 2002, Ned Jackson Lovely wrote:\n",
      "\n",
      "> In '87 a guy named Gregory Robertson noticed a fellow parachutist Debbie \n",
      "> Williams had been knocked unconscious. He shifted so that he was head down,\n",
      "> hit about 200 mi/h, and caught up with her and pulled her chute with 10 seconds\n",
      "> to spare.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# extract the email body from the email string\n",
    "\n",
    "def extract_email_body(email_str):\n",
    "    # check if the email string contains at least two new lines\n",
    "    if '\\n\\n' not in email_str:\n",
    "        return email_str\n",
    "\n",
    "    # the email body is between the first two new lines\n",
    "    body = email_str.split('\\n\\n', 1)[1]\n",
    "\n",
    "    # remove the footer \n",
    "    while body[-1] == '\\n':\n",
    "        body = body[:-1]\n",
    "\n",
    "    body = body.split('\\n\\n')[:-1]\n",
    "    body = '\\n\\n'.join(body)\n",
    "\n",
    "    return body\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "test = extract_email_body(df['email'][598])\n",
    "print(test)\n",
    "print(\"-------------------------------------\")\n",
    "#print(df[0][598])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Mon, 9 Sep 2002, Ned Jackson Lovely wrote:\n",
      "\n",
      "> In '87 a guy named Gregory Robertson noticed a fellow parachutist Debbie \n",
      "> Williams had been knocked unconscious. He shifted so that he was head down,\n",
      "> hit about 200 mi/h, and caught up with her and pulled her chute with 10 seconds\n",
      "> to spare.\n"
     ]
    }
   ],
   "source": [
    "df['email'] = df['email'].apply(extract_email_body)\n",
    "        \n",
    "print(df['email'][598])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def convert_url(words):\n",
    "    for i, word in enumerate(words):\n",
    "        url = re.match(\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|\" \\\n",
    "                       \"[!*\\(\\), ]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", word)\n",
    "        \n",
    "        if url:\n",
    "            words[i] = 'URL'\n",
    "\n",
    "    return words\n",
    "\n",
    "def convert_num(words):\n",
    "    words = list(words)  # convert string to list of characters\n",
    "    for i, word in enumerate(words):\n",
    "        if word.isdigit():\n",
    "            words[i] = 'NUM '\n",
    "    return ''.join(words)  # convert list back to string\n",
    "\n",
    "def clean_text(text):\n",
    "  text = re.sub(r'[^\\w\\s]', '', text) #to remove ponctuation\n",
    "  text = re.sub(r'\\d+', '', text) #to remove spacing\n",
    "  text = text.lower()\n",
    "\n",
    "  return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on mon num sep numnumnumnum ned jackson lovely wrote\n",
      "\n",
      " in numnum a guy named gregory robertson noticed a fellow parachutist debbie \n",
      " williams had been knocked unconscious he shifted so that he was head down\n",
      " hit about numnumnum mih and caught up with her and pulled her chute with numnum seconds\n",
      " to spare\n"
     ]
    }
   ],
   "source": [
    "df['email'] = df['email'].apply(convert_url)\n",
    "\n",
    "df['email'] = df['email'].apply(convert_num)\n",
    "\n",
    "df['email'] = df['email'].apply(clean_text)\n",
    "\n",
    "print(df['email'][598])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date        wed numnum aug numnumnumnum nu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>martin a posted\\ntassos papadopoulos the greek...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>man threatens explosion in moscow \\n\\nthursday...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>klez the virus that wont die\\n \\nalready the m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on wed aug numnum numnumnumnum at numnumnumnum...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4193</th>\n",
       "      <td>greetings from geocachingcom \\n\\n\\nrecent cach...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4194</th>\n",
       "      <td>i am trying to secure three of four virtual ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195</th>\n",
       "      <td>filled with useful examples and the depth clar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4196</th>\n",
       "      <td>linuxannounce digest numnumnum volume num     ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4197</th>\n",
       "      <td>\\n\\n\\nthis is an official mailing from source...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4198 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  email  label\n",
       "0         date        wed numnum aug numnumnumnum nu...      0\n",
       "1     martin a posted\\ntassos papadopoulos the greek...      0\n",
       "2     man threatens explosion in moscow \\n\\nthursday...      0\n",
       "3     klez the virus that wont die\\n \\nalready the m...      0\n",
       "4     on wed aug numnum numnumnumnum at numnumnumnum...      0\n",
       "...                                                 ...    ...\n",
       "4193  greetings from geocachingcom \\n\\n\\nrecent cach...      0\n",
       "4194  i am trying to secure three of four virtual ho...      0\n",
       "4195  filled with useful examples and the depth clar...      0\n",
       "4196  linuxannounce digest numnumnum volume num     ...      0\n",
       "4197   \\n\\n\\nthis is an official mailing from source...      0\n",
       "\n",
       "[4198 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4198, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3358,) (840,)\n",
      "(3358,) (840,)\n"
     ]
    }
   ],
   "source": [
    "# splitting the emails and the labels\n",
    "X = df['email']\n",
    "y = df['label']\n",
    "\n",
    "# splitting the data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3358, 84743) (840, 84743)\n"
     ]
    }
   ],
   "source": [
    "#transform the emails to numerical data\n",
    "vectorizer = TfidfVectorizer(min_df=1 , stop_words='english' , lowercase=True)\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "print(X_train_vec.shape, X_test_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the labels to ints\n",
    "\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "964     when brickbats or fox exposes the folly of gov...\n",
      "239     hardware acceleration for ssl makes sense sinc...\n",
      "2387    url httpwwwnewsisfreecomclicknumnumnumnumnumnu...\n",
      "990     on fri numnum aug numnumnumnum robert harley w...\n",
      "108     on fri numnum aug numnumnumnum tom wrote\\n\\n f...\n",
      "                              ...                        \n",
      "3444    barrister adewale coker chambers\\nlegal practi...\n",
      "466     i used async io on system v in the numnum numn...\n",
      "3092                                                     \n",
      "3772    we are offering you quality marketing lists wh...\n",
      "860      g  gregory alan bolcer gbolcerendeavorscom wr...\n",
      "Name: email, Length: 3358, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 70950)\t0.07682256555657738\n",
      "  (0, 53153)\t0.1286741397315909\n",
      "  (0, 78739)\t0.12047917664135062\n",
      "  (0, 58338)\t0.11293910383616924\n",
      "  (0, 76250)\t0.09823943260143536\n",
      "  (0, 58582)\t0.06538914770810232\n",
      "  (0, 82560)\t0.090699359796254\n",
      "  (0, 81241)\t0.07194568977238554\n",
      "  (0, 12305)\t0.07179068775287223\n",
      "  (0, 22740)\t0.06613052113639543\n",
      "  (0, 73620)\t0.0912086909627938\n",
      "  (0, 26597)\t0.1286741397315909\n",
      "  (0, 29713)\t0.10783028303500052\n",
      "  (0, 29158)\t0.11104955956713962\n",
      "  (0, 43633)\t0.26918035258514506\n",
      "  (0, 28565)\t0.109359304621393\n",
      "  (0, 45852)\t0.1286741397315909\n",
      "  (0, 59844)\t0.06146125068614039\n",
      "  (0, 73291)\t0.06409709622383931\n",
      "  (0, 64978)\t0.1286741397315909\n",
      "  (0, 42808)\t0.1286741397315909\n",
      "  (0, 40374)\t0.11755426771163326\n",
      "  (0, 23100)\t0.2258782076723385\n",
      "  (0, 70860)\t0.07599968856152012\n",
      "  (0, 46711)\t0.07341253072194577\n",
      "  :\t:\n",
      "  (3357, 16128)\t0.06774345321244579\n",
      "  (3357, 10185)\t0.16393676630073095\n",
      "  (3357, 70359)\t0.05014330562163666\n",
      "  (3357, 49009)\t0.05552798717988132\n",
      "  (3357, 82707)\t0.05942893516608282\n",
      "  (3357, 43252)\t0.06332254433139906\n",
      "  (3357, 53569)\t0.02618371033873777\n",
      "  (3357, 44564)\t0.05881331098324874\n",
      "  (3357, 42306)\t0.11414635801183959\n",
      "  (3357, 79211)\t0.04178834978159054\n",
      "  (3357, 81503)\t0.08079208237765453\n",
      "  (3357, 70683)\t0.042526550563807365\n",
      "  (3357, 17267)\t0.048694845893215884\n",
      "  (3357, 61353)\t0.05153234236965661\n",
      "  (3357, 45191)\t0.0743249372420376\n",
      "  (3357, 19955)\t0.03294966643358447\n",
      "  (3357, 55167)\t0.03926501069319551\n",
      "  (3357, 46433)\t0.09335762349161605\n",
      "  (3357, 41813)\t0.03745373278310954\n",
      "  (3357, 77366)\t0.06374401513686856\n",
      "  (3357, 73620)\t0.14376078155245622\n",
      "  (3357, 63288)\t0.04442223684756696\n",
      "  (3357, 54798)\t0.027465837502320695\n",
      "  (3357, 54985)\t0.023246615906038985\n",
      "  (3357, 28064)\t0.06998986804301002\n"
     ]
    }
   ],
   "source": [
    "print(X_train_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([y_train, y_train])\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Fit the model after ensuring at least two classes in the data\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(cm, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lemon\\anaconda3\\envs\\new_env\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lemon\\anaconda3\\envs\\new_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1252\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1250\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1253\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1254\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1255\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1256\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1257\u001b[0m     )\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1260\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
