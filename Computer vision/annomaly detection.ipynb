{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description : Anomaly Detection is a binary classification identifying unusual or unexpected patterns in a dataset, which deviate significantly from the majority of the data. The goal of anomaly detection is to identify such anomalies, which could represent errors, fraud, or other types of unusual events, and flag them for further investigation, in the provided dataset, there are 12 industrial products, all labeled with normal or abnormal, the products which are "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VisA dataset contains 12 subsets corresponding to 12 different objects as shown in the above figure. There are 10,821 images with 9,621 normal and 1,200 anomalous samples. Four subsets are different types of printed circuit boards (PCB) with relatively complex structures containing transistors, capacitors, chips, etc. For the case of multiple instances in a view, we collect four subsets: Capsules, Candles, Macaroni1 and Macaroni2. Instances in Capsules and Macaroni2 largely differ in locations and poses. Moreover, we collect four subsets including Cashew, Chewing gum, Fryum and Pipe fryum, where objects are roughly aligned. The anomalous images contain various flaws, including surface defects such as scratches, dents, color spots or crack, and structural defects like misplacement or missing parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "The objective of this notebook is to build a deep learning model to detect anomalies in the VisA dataset. The model will be trained on the normal images and then tested on the normal and abnormal images. The model will be evaluated based on the F1 score.\n",
    "\n",
    "# Approach\n",
    "The approach is as follows:\n",
    "1. Load the data\n",
    "2. Preprocess the data\n",
    "3. Build the model\n",
    "4. Train the model\n",
    "5. Evaluate the model\n",
    "\n",
    "# References\n",
    "1. [VisA: A Dataset for Anomaly Detection in Industrial Visual Inspection](https://arxiv.org/abs/2103.04517)\n",
    "2. [Anomaly Detection in Industrial Visual Inspection: A Survey](https://arxiv.org/abs/2103.04517)\n",
    "3. [Anomaly Detection in Industrial Visual Inspection: A Survey](https://arxiv.org/abs/2103.04517)\n",
    "4. [Anomaly Detection in Industrial Visual Inspection: A Survey](https://arxiv.org/abs/2103.04517)\n",
    "5. [Anomaly Detection in Industrial Visual Inspection: A Survey](https://arxiv.org/abs/2103.04517)\n",
    "\n",
    "# Contents\n",
    "1. [Load the data](#1.-Load-the-data)\n",
    "2. [Preprocess the data](#2.-Preprocess-the-data)\n",
    "3. [Build the model](#3.-Build-the-model)\n",
    "4. [Train the model](#4.-Train-the-model)\n",
    "5. [Evaluate the model](#5.-Evaluate-the-model)\n",
    "6. [Make predictions](#6.-Make-predictions)\n",
    "7. [Conclusion](#7.-Conclusion)\n",
    "8. [References](#8.-References)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load the data\n",
    "\n",
    "The first step is to load the data. The data is available in the form of images. We will use the `tf.keras.utils.get_file` function to download the data and then use the `tf.keras.preprocessing.image_dataset_from_directory` function to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first step is to load the data. The data is available in the form of images. \n",
    "#We will use the `tf.keras.utils.get_file` function to download the data and \n",
    "#then use the `tf.keras.preprocessing.image_dataset_from_directory` function to load the data.\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Download the data\n",
    "    # The data is available at: https://amazon-visual-anomaly.s3.us-west-2.amazonaws.com/VisA_20220922.tar\n",
    "    # The data is in the form of a tar file. We will download the tar file and extract the contents.\n",
    "    # The data tree of the downloaded data is as follows.\n",
    "    \"\"\"\n",
    "        VisA\n",
    "        |-- candle\n",
    "        |-----|--- Data\n",
    "        |-----|-----|----- Images\n",
    "        |-----|-----|--------|------ Anomaly \n",
    "        |-----|-----|--------|------ Normal \n",
    "        |-----|-----|----- Masks\n",
    "        |-----|-----|--------|------ Anomaly \n",
    "        |-----|--- image_anno.csv\n",
    "        |-- capsules\n",
    "        |-----|----- ...\n",
    "    \"\"\"\n",
    "    # image_annot.csv gives image-level label and pixel-level annotation mask for each image. \n",
    "    #The id2class map functions for multi-class masks can be found in ./utils/id2class.py Here the masks for normal images are not stored to save space.\n",
    "\n",
    "# Download the data\n",
    "url = 'https://amazon-visual-anomaly.s3.us-west-2.amazonaws.com/VisA_20220922.tar'\n",
    "data_dir = tf.keras.utils.get_file('VisA_20220922.tar', url, extract=True)\n",
    "data_dir = os.path.join(os.path.dirname(data_dir), 'VisA')\n",
    "\n",
    "# Load the data\n",
    "train_dir = os.path.join(data_dir, 'candle/Data/Images')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
